# üß† Dropout Regularization Experiments on MNIST

–ë“±–ª –∂–æ–±–∞ **Dropout** ”ô–¥—ñ—Å—ñ–Ω—ñ“£ –Ω–µ–π—Ä–æ–Ω–¥—ã“õ –∂–µ–ª—ñ–Ω—ñ“£ ”©–Ω—ñ–º–¥—ñ–ª—ñ–≥—ñ–Ω–µ ”ô—Å–µ—Ä—ñ–Ω –∑–µ—Ä—Ç—Ç–µ—É–≥–µ –∞—Ä–Ω–∞–ª“ì–∞–Ω.  
–ë–∞—Ä–ª—ã“õ —Ç”ô–∂—ñ—Ä–∏–±–µ–ª–µ—Ä **MNIST** –¥–µ—Ä–µ–∫—Ç–µ—Ä –∂–∏—ã–Ω—ã–Ω–¥–∞ –æ—Ä—ã–Ω–¥–∞–ª–¥—ã –∂”ô–Ω–µ **src1.ipynb** –Ω–æ—É—Ç–±—É–∫ —Ñ–∞–π–ª—ã–Ω–¥–∞ –∂“Ø–∑–µ–≥–µ –∞—Å—ã—Ä—ã–ª–¥—ã.

---

## üìò –ñ–æ–±–∞–Ω—ã“£ –º–∞“õ—Å–∞—Ç—ã
Dropout –∂”ô–Ω–µ –±–∞—Å“õ–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ”ô–¥—ñ—Å—Ç–µ—Ä—ñ (L2, Max-Norm) –Ω–µ–π—Ä–æ–Ω–¥—ã“õ –∂–µ–ª—ñ–Ω—ñ“£ –∞—Ä—Ç—ã“õ “Ø–π—Ä–µ–Ω—É—ñ–Ω (overfitting) –∞–∑–∞–π—Ç–∞ –∞–ª–∞ –º–∞ ‚Äî —Å–æ–Ω—ã —Ç”ô–∂—ñ—Ä–∏–±–µ –∂“Ø–∑—ñ–Ω–¥–µ —Ç–µ–∫—Å–µ—Ä—É.

---

## ‚öôÔ∏è –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—Ç—ñ–∫ –æ—Ä—Ç–∞
- **Python:** 3.10  
- **–§—Ä–µ–π–º–≤–æ—Ä–∫:** PyTorch 2.x  
- **–û—Ä—ã–Ω–¥–∞—É “õ“±—Ä—ã–ª“ì—ã—Å—ã:** CPU  
- **–ù–æ—É—Ç–±—É–∫:** `src1.ipynb`

---

## üì¶ “ö–æ–ª–¥–∞–Ω—ã–ª“ì–∞–Ω –∫—ñ—Ç–∞–ø—Ö–∞–Ω–∞–ª–∞—Ä
`torch`, `torchvision`, `numpy`, `matplotlib`, `random`, `time`

–ë–∞—Ä–ª—ã“õ –∫—ñ—Ç–∞–ø—Ö–∞–Ω–∞–ª–∞—Ä–¥—ã –æ—Ä–Ω–∞—Ç—É:
```bash
pip install torch torchvision matplotlib numpy
```

---

## üß© –ú–æ–¥–µ–ª—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Å—ã
```
Input (784) ‚Üí Dense(512, ReLU) ‚Üí Dropout(p)
             ‚Üí Dense(512, ReLU) ‚Üí Dropout(p)
             ‚Üí Output(10)
```
–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: `SGD (momentum=0.9)`  
“ö–∞—Ç–µ–ª—ñ–∫ —Ñ—É–Ω–∫—Ü–∏—è—Å—ã: `CrossEntropyLoss`

---

## üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—Ç–µ—Ä
1. **Learning Rate —Ç–∞“£–¥–∞—É:** [0.001, 0.01, 0.05, 0.1]  
   ‚Üí –û–ø—Ç–∏–º–∞–ª–¥—ã—Å—ã: `lr = 0.01`
2. **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è —Å–∞–ª—ã—Å—Ç—ã—Ä—É:** L2, Dropout, Dropout+L2, Dropout+MaxNorm  
   ‚Üí –ï“£ –∂–∞“õ—Å—ã –Ω”ô—Ç–∏–∂–µ: Dropout+L2 = ~98%
3. **Dropout –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ñ:** p ‚àà [0.0, 0.2, 0.5, 0.8]  
   ‚Üí –û–ø—Ç–∏–º–∞–ª–¥—ã –º”ô–Ω: `p = 0.2`
4. **–î–µ—Ä–µ–∫—Ç–µ—Ä –∫”©–ª–µ–º—ñ:** [500, 10k, 30k, 60k]  
   ‚Üí 60k –∫–µ–∑—ñ–Ω–¥–µ –¥”ô–ª–¥—ñ–∫ 98%

---

## üöÄ “ö–∞–ª–∞–π –æ—Ä—ã–Ω–¥–∞—É –∫–µ—Ä–µ–∫
### 1. –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π–¥—ñ –∫”©—à—ñ—Ä—É
```bash
git clone https://github.com/<username>/<repo-name>.git
cd <repo-name>
```
### 2. –ü–∞–∫–µ—Ç—Ç–µ—Ä–¥—ñ –æ—Ä–Ω–∞—Ç—É
```bash
pip install torch torchvision matplotlib numpy
```
### 3. –ù–æ—É—Ç–±—É–∫—Ç—ñ –∞—à—É
```bash
jupyter notebook src1.ipynb
```
–ù–µ–º–µ—Å–µ Google Colab –∞—Ä“õ—ã–ª—ã:
```
Runtime ‚Üí Run all
```

---

## üìä –ù”ô—Ç–∏–∂–µ–ª–µ—Ä
| –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç | –ï“£ –∂–∞“õ—Å—ã –¥”ô–ª–¥—ñ–∫ | Dropout (p) | LR | –ï—Å–∫–µ—Ä—Ç–ø–µ |
|--------------|----------------|--------------|----|-----------|
| Learning Rate Test | 97‚Äì98% | 0.5 | 0.01 | –û–ø—Ç–∏–º–∞–ª–¥—ã |
| Dropout vs L2 | **98.0%** | 0.2 | 0.01 | –ï“£ –∂–∞“õ—Å—ã –∫–æ–º–±–∏–Ω–∞—Ü–∏—è |
| Dropout p Effect | 98.1% | **0.2** | 0.01 | –û–ø—Ç–∏–º–∞–ª–¥—ã p |
| Dataset Size | 98.1% | 0.5 | 0.01 | 60k –º—ã—Å–∞–ª–º–µ–Ω |

---

## üìà –ì—Ä–∞—Ñ–∏–∫—Ç–µ—Ä
–ù–æ—É—Ç–±—É–∫—Ç–∞ –∞–≤—Ç–æ–º–∞—Ç—Ç—ã —Ç“Ø—Ä–¥–µ –∫”©—Ä—Å–µ—Ç—ñ–ª–µ–¥—ñ:
- Train Loss –¥–∏–Ω–∞–º–∏–∫–∞—Å—ã  
- Test Accuracy ”©–∑–≥–µ—Ä—ñ—Å—ñ  
- Dropout –∂”ô–Ω–µ L2 ”ô—Å–µ—Ä—ñ–Ω —Å–∞–ª—ã—Å—Ç—ã—Ä—É

---

## üß† “ö–æ—Ä—ã—Ç—ã–Ω–¥—ã
- Dropout ”ô–¥—ñ—Å—ñ –∞—Ä—Ç—ã“õ “Ø–π—Ä–µ–Ω—É–¥—ñ –∞–∑–∞–π—Ç–∞–¥—ã.  
- Dropout + L2 –∫–æ–º–±–∏–Ω–∞—Ü–∏—è—Å—ã –µ“£ –∂–∞“õ—Å—ã –Ω”ô—Ç–∏–∂–µ –∫”©—Ä—Å–µ—Ç—Ç—ñ.  
- –û–ø—Ç–∏–º–∞–ª–¥—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä: `p=0.2`, `lr=0.01`, `momentum=0.9`.  
- “ö–∞—Ä–∞–ø–∞–π—ã–º –º–æ–¥–µ–ª—å–º–µ–Ω 98% –¥”ô–ª–¥—ñ–∫–∫–µ –∂–µ—Ç—É–≥–µ –±–æ–ª–∞–¥—ã.
